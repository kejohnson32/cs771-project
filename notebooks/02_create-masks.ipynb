{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Create Water Segmentation Masks with SAM 2\n",
    "\n",
    "This notebook uses SAM 2 to create segmentation masks for water surfaces across a sequence of river camera images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-heading",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera and directory configuration\n",
    "camera_id = 'WI_East_Branch_Pecatonica_River_near_Blanchardville_Bullet'\n",
    "images_dir = f'{camera_id}/images'\n",
    "csv_path = f'{camera_id}/images_and_data.csv'\n",
    "\n",
    "# SAM 2 model configuration\n",
    "sam2_checkpoint = \"../checkpoints/sam2.1_hiera_tiny.pt\"\n",
    "model_cfg = \"configs/sam2.1/sam2.1_hiera_t.yaml\"\n",
    "# For better quality (but slower), use the large model:\n",
    "# sam2_checkpoint = \"../checkpoints/sam2.1_hiera_large.pt\"\n",
    "# model_cfg = \"../configs/sam2.1_hiera_l.yaml\"\n",
    "\n",
    "# Output directory for masks\n",
    "output_dir = f'{camera_id}/masks'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Temporary directory for SAM 2 (requires sequential numbered images)\n",
    "sam_video_dir = f'{camera_id}/SAM'\n",
    "os.makedirs(sam_video_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "device-heading",
   "metadata": {},
   "source": [
    "## Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "device-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable MPS fallback for unsupported operations\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "# Select the device for computation\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    # Use bfloat16 for the entire notebook\n",
    "    torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "    # Turn on tfloat32 for Ampere GPUs\n",
    "    if torch.cuda.get_device_properties(0).major >= 8:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "elif device.type == \"mps\":\n",
    "    print(\"\\nNote: MPS support is preliminary. SAM 2 may give different results on MPS vs CUDA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepare-heading",
   "metadata": {},
   "source": [
    "## Prepare Images for SAM 2\n",
    "\n",
    "SAM 2 requires images to be sequentially numbered (e.g., 00000.jpg, 00001.jpg, ...). We'll create symbolic links with sequential names instead of copying files to save space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-images",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all images, sorted by filename\n",
    "image_files = sorted([\n",
    "    f for f in os.listdir(images_dir)\n",
    "    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "])\n",
    "\n",
    "print(f\"Found {len(image_files)} images\")\n",
    "\n",
    "# Create symbolic links with sequential names (instead of copying)\n",
    "# Symlinks are like shortcuts - they don't duplicate the data\n",
    "for i, filename in enumerate(image_files):\n",
    "    src_path = os.path.abspath(os.path.join(images_dir, filename))\n",
    "    new_filename = f\"{i:05d}.jpg\"  # 00000.jpg, 00001.jpg, etc.\n",
    "    dst_path = os.path.join(sam_video_dir, new_filename)\n",
    "    \n",
    "    # Remove existing symlink if it exists\n",
    "    if os.path.islink(dst_path) or os.path.exists(dst_path):\n",
    "        os.remove(dst_path)\n",
    "    \n",
    "    # Create symbolic link\n",
    "    os.symlink(src_path, dst_path)\n",
    "\n",
    "print(f\"Created symbolic links in {sam_video_dir}\")\n",
    "print(\"(No data duplication - symlinks point to original files)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-frame-names",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan all the JPEG frame names in the SAM video directory\n",
    "frame_names = [\n",
    "    p for p in os.listdir(sam_video_dir)\n",
    "    if os.path.splitext(p)[-1] in [\".jpg\", \".jpeg\", \".JPG\", \".JPEG\"]\n",
    "]\n",
    "frame_names.sort(key=lambda p: int(os.path.splitext(p)[0]))\n",
    "\n",
    "print(f\"Found {len(frame_names)} frames for SAM 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-first-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first frame\n",
    "frame_idx = 0\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(f\"Frame {frame_idx}\")\n",
    "plt.imshow(Image.open(os.path.join(sam_video_dir, frame_names[frame_idx])))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sam2-heading",
   "metadata": {},
   "source": [
    "## Load SAM 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-sam2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam2.build_sam import build_sam2_video_predictor\n",
    "\n",
    "predictor = build_sam2_video_predictor(model_cfg, sam2_checkpoint, device=device)\n",
    "print(\"SAM 2 model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "init-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize inference state\n",
    "inference_state = predictor.init_state(video_path=sam_video_dir)\n",
    "print(\"Inference state initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helper-heading",
   "metadata": {},
   "source": [
    "## Helper Functions for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helper-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, obj_id=None, random_color=False):\n",
    "    \"\"\"Display a segmentation mask on the given axes.\"\"\"\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        cmap = plt.get_cmap(\"tab10\")\n",
    "        cmap_idx = 0 if obj_id is None else obj_id\n",
    "        color = np.array([*cmap(cmap_idx)[:3], 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=200):\n",
    "    \"\"\"Display click points on the given axes.\"\"\"\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', \n",
    "               s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', \n",
    "               s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "\n",
    "\n",
    "def show_box(box, ax):\n",
    "    \"\"\"Display a bounding box on the given axes.\"\"\"\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', \n",
    "                                facecolor=(0, 0, 0, 0), lw=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "segment-heading",
   "metadata": {},
   "source": [
    "## Interactive Water Segmentation\n",
    "\n",
    "### Step 1: Add initial clicks to identify water\n",
    "\n",
    "Look at the first frame above and identify coordinates where the water is visible.\n",
    "Add positive clicks (label=1) on the water surface.\n",
    "\n",
    "**Instructions:**\n",
    "1. Look at the image above to identify water coordinates\n",
    "2. Update the `points` array below with (x, y) coordinates on the water\n",
    "3. If needed, add negative clicks (label=0) to exclude non-water regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add-clicks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame to annotate (typically start with frame 0)\n",
    "ann_frame_idx = 0\n",
    "ann_obj_id = 1  # Object ID for water (can be any unique integer)\n",
    "\n",
    "# Add click coordinates here - MODIFY THESE COORDINATES based on your image\n",
    "# Example: clicking on water surface locations\n",
    "# You may need to run this cell multiple times with different points to refine\n",
    "points = np.array([\n",
    "    [750, 800],  # First click on water - MODIFY THESE COORDINATES\n",
    "    # [250, 850],  # Uncomment and modify to add more clicks\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Labels: 1 = positive click (add region), 0 = negative click (remove region)\n",
    "labels = np.array([1], np.int32)  # Update size to match number of points\n",
    "\n",
    "# Add the prompts\n",
    "_, out_obj_ids, out_mask_logits = predictor.add_new_points_or_box(\n",
    "    inference_state=inference_state,\n",
    "    frame_idx=ann_frame_idx,\n",
    "    obj_id=ann_obj_id,\n",
    "    points=points,\n",
    "    labels=labels,\n",
    ")\n",
    "\n",
    "# Show the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(f\"Frame {ann_frame_idx} - Water Segmentation\")\n",
    "plt.imshow(Image.open(os.path.join(sam_video_dir, frame_names[ann_frame_idx])))\n",
    "show_points(points, labels, plt.gca())\n",
    "show_mask((out_mask_logits[0] > 0.0).cpu().numpy(), plt.gca(), obj_id=out_obj_ids[0])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nIf the mask doesn't look right, modify the points above and re-run this cell.\")\n",
    "print(\"You can add more points or add negative clicks (label=0) to refine.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refine-heading",
   "metadata": {},
   "source": [
    "### Step 2 (Optional): Refine with additional clicks\n",
    "\n",
    "If the mask above isn't perfect, add more clicks to refine it.\n",
    "You can skip this step if the mask looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refine-clicks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add refinement clicks here if needed\n",
    "# Remember to include ALL previous clicks plus new ones\n",
    "\n",
    "# Example with additional click:\n",
    "points = np.array([\n",
    "    [250, 800],  # Original click\n",
    "    [1700, 850],  # Additional positive click\n",
    "    [1100, 400],  # Negative click to remove unwanted region (label=0)\n",
    "], dtype=np.float32)\n",
    "labels = np.array([\n",
    "    1, \n",
    "    1, \n",
    "    0\n",
    "    ], np.int32)\n",
    "\n",
    "_, out_obj_ids, out_mask_logits = predictor.add_new_points_or_box(\n",
    "    inference_state=inference_state,\n",
    "    frame_idx=ann_frame_idx,\n",
    "    obj_id=ann_obj_id,\n",
    "    points=points,\n",
    "    labels=labels,\n",
    ")\n",
    "\n",
    "# Show the refined results\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(f\"Frame {ann_frame_idx} - Refined Water Segmentation\")\n",
    "plt.imshow(Image.open(os.path.join(sam_video_dir, frame_names[ann_frame_idx])))\n",
    "show_points(points, labels, plt.gca())\n",
    "show_mask((out_mask_logits[0] > 0.0).cpu().numpy(), plt.gca(), obj_id=out_obj_ids[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "propagate-heading",
   "metadata": {},
   "source": [
    "### Step 3: Propagate segmentation across all frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "propagate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run propagation throughout the video\n",
    "video_segments = {}  # Store per-frame segmentation results\n",
    "\n",
    "print(\"Propagating masks across all frames...\")\n",
    "for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(inference_state):\n",
    "    video_segments[out_frame_idx] = {\n",
    "        out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()\n",
    "        for i, out_obj_id in enumerate(out_obj_ids)\n",
    "    }\n",
    "\n",
    "print(f\"Propagation complete! Generated masks for {len(video_segments)} frames.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-heading",
   "metadata": {},
   "source": [
    "### Step 4: Visualize results on sample frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize every N frames\n",
    "vis_frame_stride = max(1, len(frame_names) // 6)  # Show ~6 frames\n",
    "\n",
    "plt.close(\"all\")\n",
    "for out_frame_idx in range(0, len(frame_names), vis_frame_stride):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.title(f\"Frame {out_frame_idx} / {len(frame_names)}\")\n",
    "    plt.imshow(Image.open(os.path.join(sam_video_dir, frame_names[out_frame_idx])))\n",
    "    for out_obj_id, out_mask in video_segments[out_frame_idx].items():\n",
    "        show_mask(out_mask, plt.gca(), obj_id=out_obj_id)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nIf the masks don't look good throughout, you may need to:\")\n",
    "print(\"1. Add refinement clicks on problem frames (see Step 5)\")\n",
    "print(\"2. Or reset and start over with better initial clicks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refine-frame-heading",
   "metadata": {},
   "source": [
    "### Step 5 (Optional): Refine masks on specific problematic frames\n",
    "\n",
    "If you notice issues on specific frames, you can add clicks to refine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refine-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and modify to refine a specific frame\n",
    "\n",
    "# # Choose a frame that needs refinement\n",
    "# problem_frame_idx = 30  # MODIFY THIS\n",
    "# ann_obj_id = 1\n",
    "\n",
    "# # Show current mask on that frame\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.title(f\"Frame {problem_frame_idx} - Before Refinement\")\n",
    "# plt.imshow(Image.open(os.path.join(sam_video_dir, frame_names[problem_frame_idx])))\n",
    "# show_mask(video_segments[problem_frame_idx][ann_obj_id], plt.gca(), obj_id=ann_obj_id)\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# # Add refinement clicks on this frame\n",
    "# points = np.array([[400, 500]], dtype=np.float32)  # MODIFY COORDINATES\n",
    "# labels = np.array([0], np.int32)  # 0 = negative click to remove region\n",
    "\n",
    "# _, _, out_mask_logits = predictor.add_new_points_or_box(\n",
    "#     inference_state=inference_state,\n",
    "#     frame_idx=problem_frame_idx,\n",
    "#     obj_id=ann_obj_id,\n",
    "#     points=points,\n",
    "#     labels=labels,\n",
    "# )\n",
    "\n",
    "# # Show refined mask\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.title(f\"Frame {problem_frame_idx} - After Refinement\")\n",
    "# plt.imshow(Image.open(os.path.join(sam_video_dir, frame_names[problem_frame_idx])))\n",
    "# show_points(points, labels, plt.gca())\n",
    "# show_mask((out_mask_logits > 0.0).cpu().numpy(), plt.gca(), obj_id=ann_obj_id)\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# # Re-run propagation to update all masks\n",
    "# print(\"Re-running propagation with refinements...\")\n",
    "# video_segments = {}\n",
    "# for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(inference_state):\n",
    "#     video_segments[out_frame_idx] = {\n",
    "#         out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()\n",
    "#         for i, out_obj_id in enumerate(out_obj_ids)\n",
    "#     }\n",
    "# print(\"Propagation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-heading",
   "metadata": {},
   "source": [
    "## Save Masks\n",
    "\n",
    "Save the water segmentation masks as numpy arrays (.npy files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-masks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks output directory\n",
    "# masks_dir = os.path.join(output_dir, 'masks_npy')\n",
    "masks_dir = output_dir\n",
    "os.makedirs(masks_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Saving masks to {masks_dir}...\")\n",
    "\n",
    "# Save each mask with corresponding original filename\n",
    "for out_frame_idx, frame_name in enumerate(frame_names):\n",
    "    frame_masks = video_segments[out_frame_idx]\n",
    "    \n",
    "    for out_obj_id, out_mask in frame_masks.items():\n",
    "        # Convert to numpy array if needed\n",
    "        mask_np = out_mask if isinstance(out_mask, np.ndarray) else np.array(out_mask)\n",
    "        \n",
    "        # Create filename based on sequential frame name and object ID\n",
    "        mask_filename = f\"{os.path.splitext(frame_name)[0]}_obj{out_obj_id}.npy\"\n",
    "        mask_path = os.path.join(masks_dir, mask_filename)\n",
    "        \n",
    "        # Save as .npy file\n",
    "        np.save(mask_path, mask_np)\n",
    "\n",
    "print(f\"\\nSaved {len(frame_names)} masks successfully!\")\n",
    "print(f\"Masks saved to: {masks_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create-mapping-heading",
   "metadata": {},
   "source": [
    "## Add Masks to Images Data CSV\n",
    "\n",
    "Add the mask filenames to the existing images_and_data.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing images and data CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"Loaded {len(df)} rows from {csv_path}\")\n",
    "\n",
    "# Create a mapping from original filename to mask filename\n",
    "filename_to_mask = {}\n",
    "for idx, original_filename in enumerate(image_files):\n",
    "    mask_filename = f\"{idx:05d}_obj1.npy\"\n",
    "    filename_to_mask[original_filename] = mask_filename\n",
    "\n",
    "# Add mask_filename column to the dataframe\n",
    "# The 'filename' column in df should match the image filenames\n",
    "df['mask_filename'] = df['image_names'].map(filename_to_mask)\n",
    "\n",
    "# Check if any filenames didn't get a mask (shouldn't happen)\n",
    "missing_masks = df['mask_filename'].isna().sum()\n",
    "if missing_masks > 0:\n",
    "    print(f\"\\nWarning: {missing_masks} rows have no corresponding mask\")\n",
    "else:\n",
    "    print(f\"\\nSuccessfully mapped all {len(df)} images to their masks\")\n",
    "\n",
    "# Save back to the same CSV file\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nUpdated {csv_path} with mask_filename column\")\n",
    "\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-heading",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Water segmentation complete! The masks have been saved and can now be used for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"WATER SEGMENTATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Camera ID: {camera_id}\")\n",
    "print(f\"Number of frames processed: {len(frame_names)}\")\n",
    "print(f\"Masks saved to: {masks_dir}\")\n",
    "print(f\"Updated CSV: {csv_path}\")\n",
    "print(f\"\\nYou can now proceed to notebook 03 for elevation map creation.\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nNote: Symbolic links are still in {sam_video_dir}\")\n",
    "print(\"You can delete them to clean up if needed (they don't use much space).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "js4fe8odun9",
   "metadata": {},
   "source": [
    "## Optional: Cleanup Symbolic Links\n",
    "\n",
    "If you want to remove the temporary symbolic links directory to clean up your workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sgi5ifyxe5n",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete the symbolic links directory\n",
    "import shutil\n",
    "if os.path.exists(sam_video_dir):\n",
    "    shutil.rmtree(sam_video_dir)\n",
    "    print(f\"Deleted {sam_video_dir}\")\n",
    "else:\n",
    "    print(\"Directory already deleted or doesn't exist\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepwater",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
